"""
æ•°æ®è¿ç§»æ¨¡å—ï¼šä»æ–‡ä»¶å­˜å‚¨è¿ç§»åˆ° SQLite æ•°æ®åº“
"""
import os
import json
import shutil
import logging
import secrets
from pathlib import Path
from datetime import datetime
import yaml

from backend.models import db, HistoryRecord, OutlinePage, TaskImage, ProviderConfig, User
from backend.utils.auth import hash_password

logger = logging.getLogger(__name__)


def ensure_users_table():
    """
    ç¡®ä¿ users è¡¨å­˜åœ¨

    ä½¿ç”¨åŸç”Ÿ SQL æ£€æŸ¥å’Œåˆ›å»ºï¼Œé¿å… ORM æ¨¡å‹ä¸æ•°æ®åº“ä¸ä¸€è‡´çš„é—®é¢˜
    """
    from sqlalchemy import text, inspect

    inspector = inspect(db.engine)
    tables = inspector.get_table_names()

    if 'users' not in tables:
        logger.info("ğŸ“‹ åˆ›å»º users è¡¨...")
        db.session.execute(text("""
            CREATE TABLE users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username VARCHAR(50) NOT NULL UNIQUE,
                password_hash VARCHAR(255) NOT NULL,
                is_active BOOLEAN DEFAULT 1,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_login_at DATETIME
            )
        """))
        db.session.commit()
        logger.info("âœ… users è¡¨åˆ›å»ºå®Œæˆ")


def ensure_user_id_columns():
    """
    ç¡®ä¿ history_records å’Œ provider_configs è¡¨æœ‰ user_id åˆ—

    ä½¿ç”¨åŸç”Ÿ SQL è¿›è¡Œ schema è¿ç§»ï¼Œé¿å… ORM æŸ¥è¯¢å¤±è´¥
    """
    from sqlalchemy import text, inspect

    inspector = inspect(db.engine)

    # æ£€æŸ¥ history_records è¡¨
    if 'history_records' in inspector.get_table_names():
        columns = [col['name'] for col in inspector.get_columns('history_records')]
        if 'user_id' not in columns:
            logger.info("ğŸ“‹ ä¸º history_records è¡¨æ·»åŠ  user_id åˆ—...")
            db.session.execute(text(
                "ALTER TABLE history_records ADD COLUMN user_id INTEGER REFERENCES users(id)"
            ))
            db.session.commit()
            logger.info("âœ… history_records.user_id åˆ—æ·»åŠ å®Œæˆ")

    # æ£€æŸ¥ provider_configs è¡¨
    if 'provider_configs' in inspector.get_table_names():
        columns = [col['name'] for col in inspector.get_columns('provider_configs')]
        if 'user_id' not in columns:
            logger.info("ğŸ“‹ ä¸º provider_configs è¡¨æ·»åŠ  user_id åˆ—...")
            db.session.execute(text(
                "ALTER TABLE provider_configs ADD COLUMN user_id INTEGER REFERENCES users(id)"
            ))
            db.session.commit()
            logger.info("âœ… provider_configs.user_id åˆ—æ·»åŠ å®Œæˆ")


def get_project_root() -> Path:
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    return Path(__file__).parent.parent


def backup_old_files():
    """å¤‡ä»½æ—§çš„æ•°æ®æ–‡ä»¶"""
    project_root = get_project_root()
    backup_dir = project_root / 'backup' / datetime.now().strftime('%Y%m%d_%H%M%S')

    files_to_backup = [
        project_root / 'history' / 'index.json',
        project_root / 'text_providers.yaml',
        project_root / 'image_providers.yaml',
    ]

    # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å¤‡ä»½çš„æ–‡ä»¶
    has_files = False
    for f in files_to_backup:
        if f.exists():
            has_files = True
            break

    if not has_files:
        logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤‡ä»½çš„æ—§æ•°æ®æ–‡ä»¶")
        return None

    # åˆ›å»ºå¤‡ä»½ç›®å½•
    backup_dir.mkdir(parents=True, exist_ok=True)

    # å¤‡ä»½æ–‡ä»¶
    for f in files_to_backup:
        if f.exists():
            dest = backup_dir / f.name
            shutil.copy2(f, dest)
            logger.info(f"ğŸ“¦ å·²å¤‡ä»½: {f.name} -> {dest}")

    # å¤‡ä»½å†å²è®°å½• JSON æ–‡ä»¶
    history_dir = project_root / 'history'
    if history_dir.exists():
        for json_file in history_dir.glob('*.json'):
            if json_file.name != 'index.json':
                dest = backup_dir / json_file.name
                shutil.copy2(json_file, dest)
                logger.info(f"ğŸ“¦ å·²å¤‡ä»½: {json_file.name}")

    logger.info(f"âœ… å¤‡ä»½å®Œæˆ: {backup_dir}")
    return backup_dir


def migrate_history_records():
    """è¿ç§»å†å²è®°å½•"""
    project_root = get_project_root()
    history_dir = project_root / 'history'
    index_file = history_dir / 'index.json'

    if not index_file.exists():
        logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ° index.jsonï¼Œè·³è¿‡å†å²è®°å½•è¿ç§»")
        return 0

    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²æœ‰æ•°æ®
    existing_count = HistoryRecord.query.count()
    if existing_count > 0:
        logger.info(f"ğŸ“Š æ•°æ®åº“å·²æœ‰ {existing_count} æ¡å†å²è®°å½•ï¼Œè·³è¿‡è¿ç§»")
        return 0

    try:
        with open(index_file, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
    except Exception as e:
        logger.error(f"âŒ è¯»å– index.json å¤±è´¥: {e}")
        return 0

    records = index_data.get('records', [])
    migrated_count = 0

    for record_meta in records:
        record_id = record_meta.get('id')
        if not record_id:
            continue

        # è¯»å–å®Œæ•´è®°å½•æ–‡ä»¶
        record_file = history_dir / f"{record_id}.json"
        if not record_file.exists():
            logger.warning(f"âš ï¸ è®°å½•æ–‡ä»¶ä¸å­˜åœ¨: {record_file}")
            continue

        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                record_data = json.load(f)
        except Exception as e:
            logger.error(f"âŒ è¯»å–è®°å½•æ–‡ä»¶å¤±è´¥ {record_file}: {e}")
            continue

        try:
            # åˆ›å»ºå†å²è®°å½•
            history_record = HistoryRecord(
                id=record_id,
                title=record_data.get('title', ''),
                status=record_data.get('status', 'draft'),
                thumbnail=record_data.get('thumbnail'),
                task_id=record_data.get('images', {}).get('task_id'),
                outline_text=record_data.get('outline', {}).get('raw', ''),
                created_at=datetime.fromisoformat(record_data.get('created_at', datetime.utcnow().isoformat())),
                updated_at=datetime.fromisoformat(record_data.get('updated_at', datetime.utcnow().isoformat()))
            )
            db.session.add(history_record)

            # åˆ›å»ºå¤§çº²é¡µé¢
            pages = record_data.get('outline', {}).get('pages', [])
            for page in pages:
                outline_page = OutlinePage(
                    record_id=record_id,
                    page_index=page.get('index', 0),
                    page_type=page.get('type', 'content'),
                    content=page.get('content', '')
                )
                db.session.add(outline_page)

            # åˆ›å»ºä»»åŠ¡å›¾ç‰‡è®°å½•
            images = record_data.get('images', {}).get('generated', [])
            for idx, filename in enumerate(images):
                task_image = TaskImage(
                    record_id=record_id,
                    image_index=idx,
                    filename=filename
                )
                db.session.add(task_image)

            db.session.commit()
            migrated_count += 1
            logger.debug(f"âœ… è¿ç§»è®°å½•: {record_id} - {record_data.get('title', '')[:30]}")

        except Exception as e:
            db.session.rollback()
            logger.error(f"âŒ è¿ç§»è®°å½•å¤±è´¥ {record_id}: {e}")
            continue

    logger.info(f"âœ… å†å²è®°å½•è¿ç§»å®Œæˆ: å…±è¿ç§» {migrated_count} æ¡è®°å½•")
    return migrated_count


def migrate_provider_configs():
    """è¿ç§»æœåŠ¡å•†é…ç½®"""
    project_root = get_project_root()

    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²æœ‰é…ç½®
    existing_count = ProviderConfig.query.count()
    if existing_count > 0:
        logger.info(f"ğŸ“Š æ•°æ®åº“å·²æœ‰ {existing_count} æ¡é…ç½®ï¼Œè·³è¿‡è¿ç§»")
        return 0

    migrated_count = 0

    # è¿ç§»æ–‡æœ¬æœåŠ¡å•†é…ç½®
    text_config_file = project_root / 'text_providers.yaml'
    if text_config_file.exists():
        try:
            with open(text_config_file, 'r', encoding='utf-8') as f:
                text_config = yaml.safe_load(f) or {}

            active_provider = text_config.get('active_provider', '')
            providers = text_config.get('providers', {})

            for name, config in providers.items():
                # æå–æ ¸å¿ƒå­—æ®µï¼Œå…¶ä½™æ”¾å…¥ extra_config
                extra = {}
                for key in ['temperature', 'max_output_tokens']:
                    if key in config:
                        extra[key] = config[key]

                provider = ProviderConfig(
                    category='text',
                    name=name,
                    provider_type=config.get('type', 'openai_compatible'),
                    api_key=config.get('api_key', ''),
                    base_url=config.get('base_url'),
                    model=config.get('model'),
                    is_active=(name == active_provider),
                    extra_config=json.dumps(extra) if extra else None
                )
                db.session.add(provider)
                migrated_count += 1

            db.session.commit()
            logger.info(f"âœ… æ–‡æœ¬æœåŠ¡å•†é…ç½®è¿ç§»å®Œæˆ: {len(providers)} ä¸ª")

        except Exception as e:
            db.session.rollback()
            logger.error(f"âŒ è¿ç§»æ–‡æœ¬é…ç½®å¤±è´¥: {e}")

    # è¿ç§»å›¾ç‰‡æœåŠ¡å•†é…ç½®
    image_config_file = project_root / 'image_providers.yaml'
    if image_config_file.exists():
        try:
            with open(image_config_file, 'r', encoding='utf-8') as f:
                image_config = yaml.safe_load(f) or {}

            active_provider = image_config.get('active_provider', '')
            providers = image_config.get('providers', {})

            for name, config in providers.items():
                # æå–æ ¸å¿ƒå­—æ®µï¼Œå…¶ä½™æ”¾å…¥ extra_config
                extra = {}
                for key in ['high_concurrency', 'short_prompt', 'default_aspect_ratio',
                            'temperature', 'image_size', 'endpoint_type']:
                    if key in config:
                        extra[key] = config[key]

                provider = ProviderConfig(
                    category='image',
                    name=name,
                    provider_type=config.get('type', 'google_genai'),
                    api_key=config.get('api_key', ''),
                    base_url=config.get('base_url'),
                    model=config.get('model'),
                    is_active=(name == active_provider),
                    extra_config=json.dumps(extra) if extra else None
                )
                db.session.add(provider)
                migrated_count += 1

            db.session.commit()
            logger.info(f"âœ… å›¾ç‰‡æœåŠ¡å•†é…ç½®è¿ç§»å®Œæˆ: {len(providers)} ä¸ª")

        except Exception as e:
            db.session.rollback()
            logger.error(f"âŒ è¿ç§»å›¾ç‰‡é…ç½®å¤±è´¥: {e}")

    return migrated_count


def get_or_create_default_user() -> int:
    """
    è·å–æˆ–åˆ›å»ºé»˜è®¤ç”¨æˆ·

    Returns:
        é»˜è®¤ç”¨æˆ·çš„ ID
    """
    default_username = 'default'

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    user = User.query.filter_by(username=default_username).first()
    if user:
        return user.id

    # åˆ›å»ºé»˜è®¤ç”¨æˆ·ï¼ˆä½¿ç”¨éšæœºå¯†ç ï¼Œä»…ç”¨äºæ•°æ®å…³è”ï¼‰
    random_password = secrets.token_urlsafe(32)
    user = User(
        username=default_username,
        password_hash=hash_password(random_password),
        is_active=True,
        created_at=datetime.utcnow()
    )
    db.session.add(user)
    db.session.commit()

    logger.info(f"âœ… å·²åˆ›å»ºé»˜è®¤ç”¨æˆ·: {default_username}")
    return user.id


def migrate_orphan_records():
    """
    å°†æ²¡æœ‰ user_id çš„è®°å½•å…³è”åˆ°é»˜è®¤ç”¨æˆ·

    Returns:
        è¿ç§»çš„è®°å½•æ•°
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰å­¤å„¿è®°å½•
    orphan_history = HistoryRecord.query.filter_by(user_id=None).count()
    orphan_config = ProviderConfig.query.filter_by(user_id=None).count()

    if orphan_history == 0 and orphan_config == 0:
        logger.info("ğŸ“Š æ²¡æœ‰éœ€è¦å…³è”ç”¨æˆ·çš„å­¤å„¿è®°å½•")
        return 0

    # è·å–æˆ–åˆ›å»ºé»˜è®¤ç”¨æˆ·
    default_user_id = get_or_create_default_user()

    # æ›´æ–° HistoryRecord
    if orphan_history > 0:
        HistoryRecord.query.filter_by(user_id=None).update({'user_id': default_user_id})
        logger.info(f"âœ… å·²å°† {orphan_history} æ¡å†å²è®°å½•å…³è”åˆ°é»˜è®¤ç”¨æˆ·")

    # æ›´æ–° ProviderConfig
    if orphan_config > 0:
        ProviderConfig.query.filter_by(user_id=None).update({'user_id': default_user_id})
        logger.info(f"âœ… å·²å°† {orphan_config} æ¡é…ç½®å…³è”åˆ°é»˜è®¤ç”¨æˆ·")

    db.session.commit()

    return orphan_history + orphan_config


def check_and_migrate():
    """
    æ£€æŸ¥å¹¶æ‰§è¡Œè¿ç§»

    Returns:
        bool: æ˜¯å¦æ‰§è¡Œäº†è¿ç§»
    """
    # é¦–å…ˆç¡®ä¿æ•°æ®åº“ schema æ˜¯æœ€æ–°çš„
    # è¿™å¿…é¡»åœ¨ä»»ä½• ORM æŸ¥è¯¢ä¹‹å‰æ‰§è¡Œ
    ensure_users_table()
    ensure_user_id_columns()

    project_root = get_project_root()

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—§æ•°æ®æ–‡ä»¶
    has_old_data = (
        (project_root / 'history' / 'index.json').exists() or
        (project_root / 'text_providers.yaml').exists() or
        (project_root / 'image_providers.yaml').exists()
    )

    if not has_old_data:
        # å³ä½¿æ²¡æœ‰æ—§æ•°æ®ï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦æœ‰å­¤å„¿è®°å½•éœ€è¦å…³è”
        orphan_migrated = migrate_orphan_records()
        if orphan_migrated > 0:
            logger.info(f"âœ… å·²å°† {orphan_migrated} æ¡è®°å½•å…³è”åˆ°é»˜è®¤ç”¨æˆ·")
        else:
            logger.info("ğŸ“ æ²¡æœ‰å‘ç°æ—§æ•°æ®æ–‡ä»¶ï¼Œæ— éœ€è¿ç§»")
        return orphan_migrated > 0

    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦ä¸ºç©º
    history_count = HistoryRecord.query.count()
    config_count = ProviderConfig.query.count()

    if history_count > 0 or config_count > 0:
        logger.info(f"ğŸ“Š æ•°æ®åº“å·²æœ‰æ•°æ® (å†å²è®°å½•: {history_count}, é…ç½®: {config_count})ï¼Œè·³è¿‡æ–‡ä»¶è¿ç§»")
        # å³ä¾¿è·³è¿‡æ–‡ä»¶è¿ç§»ï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦æœ‰å­¤å„¿è®°å½•
        orphan_migrated = migrate_orphan_records()
        return orphan_migrated > 0

    logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®è¿ç§»...")

    # å¤‡ä»½æ—§æ–‡ä»¶
    backup_old_files()

    # è¿ç§»æ•°æ®
    history_migrated = migrate_history_records()
    config_migrated = migrate_provider_configs()

    logger.info(f"âœ… è¿ç§»å®Œæˆ: å†å²è®°å½• {history_migrated} æ¡, é…ç½® {config_migrated} æ¡")

    # å°†å­¤å„¿è®°å½•å…³è”åˆ°é»˜è®¤ç”¨æˆ·
    orphan_migrated = migrate_orphan_records()
    if orphan_migrated > 0:
        logger.info(f"âœ… å·²å°† {orphan_migrated} æ¡è®°å½•å…³è”åˆ°é»˜è®¤ç”¨æˆ·")

    return True


def run_migration():
    """æ‰‹åŠ¨è¿è¡Œè¿ç§»ï¼ˆç”¨äºå‘½ä»¤è¡Œè°ƒç”¨ï¼‰"""
    from backend.app import create_app

    app = create_app()
    with app.app_context():
        check_and_migrate()


if __name__ == '__main__':
    run_migration()
